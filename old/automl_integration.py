import pandas as pd
import numpy as np
from old.yaml_system_test import RecommendationEngine, RuleSet
from specific_preprocessing_examples import SpecificPreprocessingMethods
import streamlit as st
import json
from typing import Dict, List, Any
import logging

logger = logging.getLogger(__name__)

class AutoMLIntegration:
    """
    YAML ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œê³¼ AutoML ì‹œìŠ¤í…œì˜ í†µí•© í´ë˜ìŠ¤
    """
    
    def __init__(self, rules_file: str = "rules.yaml"):
        self.recommendation_engine = RecommendationEngine(rules_file)
        self.preprocessing_methods = SpecificPreprocessingMethods()
        
    def get_preprocessing_recommendations(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        ë°ì´í„°í”„ë ˆì„ì— ëŒ€í•œ ì „ì²˜ë¦¬ ì¶”ì²œì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            df: ì…ë ¥ ë°ì´í„°í”„ë ˆì„
            
        Returns:
            dict: ì¶”ì²œ ê²°ê³¼ ë° ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œ
        """
        
        # 1. ì¶”ì²œ ìƒì„±
        recommendations = self.recommendation_engine.run(df)
        
        # 2. ìš°ì„ ìˆœìœ„ë³„ ì •ë ¬
        priority_recommendations = self._sort_by_priority(recommendations['preprocessing'])
        
        # 3. ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œ ìƒì„±
        executable_code = self._generate_executable_code(priority_recommendations)
        
        return {
            'recommendations': priority_recommendations,
            'executable_code': executable_code,
            'summary': self._generate_summary(priority_recommendations)
        }
    
    def _sort_by_priority(self, recommendations: Dict) -> List[Dict]:
        """ìš°ì„ ìˆœìœ„ë³„ë¡œ ì¶”ì²œ ì •ë ¬"""
        priority_order = {'high': 0, 'medium': 1, 'low': 2}
        
        sorted_recs = []
        for col, rec_data in recommendations.items():
            if col.startswith('_'):
                continue
                
            priority = rec_data.get('priority', 'low')
            for action in rec_data.get('recommendations', []):
                sorted_recs.append({
                    'column': col,
                    'action': action,
                    'priority': priority,
                    'priority_order': priority_order.get(priority, 3)
                })
        
        return sorted(sorted_recs, key=lambda x: x['priority_order'])
    
    def _generate_executable_code(self, recommendations: List[Dict]) -> str:
        """ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œ ìƒì„±"""
        code_lines = [
            "import pandas as pd",
            "import numpy as np",
            "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler",
            "from sklearn.preprocessing import LabelEncoder, OneHotEncoder",
            "from scipy.stats import boxcox, yeojohnson",
            "from sklearn.feature_selection import VarianceThreshold",
            "",
            "def apply_preprocessing(df):",
            "    \"\"\"ìë™ ìƒì„±ëœ ì „ì²˜ë¦¬ í•¨ìˆ˜\"\"\"",
            "    processed_df = df.copy()",
            "    results = {}",
            ""
        ]
        
        # ê° ì¶”ì²œì— ëŒ€í•œ ì½”ë“œ ìƒì„±
        for rec in recommendations:
            column = rec['column']
            action = rec['action']
            
            # ì•¡ì…˜ë³„ ì½”ë“œ ìƒì„±
            if action == 'yeo_johnson_transform':
                code_lines.extend([
                    f"    # {column}: Yeo-Johnson ë³€í™˜",
                    f"    transformed_data, lambda_param = yeojohnson(processed_df['{column}'].dropna())",
                    f"    processed_df['{column}'] = transformed_data",
                    f"    results['{column}_yeo_johnson_lambda'] = lambda_param",
                    ""
                ])
            elif action == 'boxcox_transform':
                code_lines.extend([
                    f"    # {column}: Box-Cox ë³€í™˜",
                    f"    if (processed_df['{column}'] <= 0).any():",
                    f"        processed_df['{column}'] = processed_df['{column}'] - processed_df['{column}'].min() + 1",
                    f"    transformed_data, lambda_param = boxcox(processed_df['{column}'].dropna())",
                    f"    processed_df['{column}'] = transformed_data",
                    f"    results['{column}_boxcox_lambda'] = lambda_param",
                    ""
                ])
            elif action == 'log_transform':
                code_lines.extend([
                    f"    # {column}: ë¡œê·¸ ë³€í™˜",
                    f"    if (processed_df['{column}'] <= 0).any():",
                    f"        processed_df['{column}'] = processed_df['{column}'] - processed_df['{column}'].min() + 1",
                    f"    processed_df['{column}'] = np.log(processed_df['{column}'])",
                    ""
                ])
            elif action == 'standard_scaler':
                code_lines.extend([
                    f"    # {column}: í‘œì¤€í™”",
                    f"    scaler = StandardScaler()",
                    f"    processed_df['{column}'] = scaler.fit_transform(processed_df[['{column}']])",
                    ""
                ])
            elif action == 'one_hot_encode':
                code_lines.extend([
                    f"    # {column}: ì›í•« ì¸ì½”ë”©",
                    f"    encoded_cols = pd.get_dummies(processed_df['{column}'], prefix='{column}')",
                    f"    processed_df = pd.concat([processed_df.drop('{column}', axis=1), encoded_cols], axis=1)",
                    ""
                ])
            elif action == 'drop_column':
                code_lines.extend([
                    f"    # {column}: ì»¬ëŸ¼ ì œê±°",
                    f"    processed_df = processed_df.drop('{column}', axis=1)",
                    f"    results['{column}_dropped'] = True",
                    ""
                ])
        
        code_lines.extend([
            "    return processed_df, results",
            "",
            "# ì‚¬ìš© ì˜ˆì‹œ:",
            "# processed_df, preprocessing_results = apply_preprocessing(df)"
        ])
        
        return "\n".join(code_lines)
    
    def _generate_summary(self, recommendations: List[Dict]) -> Dict[str, Any]:
        """ì¶”ì²œ ìš”ì•½ ìƒì„±"""
        summary = {
            'total_recommendations': len(recommendations),
            'high_priority': len([r for r in recommendations if r['priority'] == 'high']),
            'medium_priority': len([r for r in recommendations if r['priority'] == 'medium']),
            'low_priority': len([r for r in recommendations if r['priority'] == 'low']),
            'action_counts': {}
        }
        
        # ì•¡ì…˜ë³„ ê°œìˆ˜ ì§‘ê³„
        for rec in recommendations:
            action = rec['action']
            summary['action_counts'][action] = summary['action_counts'].get(action, 0) + 1
        
        return summary
    
    def apply_recommendations_to_streamlit(self, df: pd.DataFrame, 
                                         selected_recommendations: List[str] = None) -> pd.DataFrame:
        """
        Streamlit í™˜ê²½ì—ì„œ ì¶”ì²œì‚¬í•­ì„ ì ìš©í•©ë‹ˆë‹¤.
        
        Args:
            df: ì…ë ¥ ë°ì´í„°í”„ë ˆì„
            selected_recommendations: ì„ íƒëœ ì¶”ì²œì‚¬í•­ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            pd.DataFrame: ì „ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„
        """
        
        processed_df = df.copy()
        
        # ì¶”ì²œ ìƒì„±
        result = self.get_preprocessing_recommendations(df)
        recommendations = result['recommendations']
        
        # ì„ íƒëœ ì¶”ì²œì‚¬í•­ë§Œ ì ìš©
        if selected_recommendations:
            recommendations = [r for r in recommendations if r['action'] in selected_recommendations]
        
        # ì¶”ì²œì‚¬í•­ ì ìš©
        for rec in recommendations:
            column = rec['column']
            action = rec['action']
            
            try:
                if action == 'yeo_johnson_transform':
                    processed_df[column] = self.preprocessing_methods.yeo_johnson_transform(
                        processed_df[column], column)
                elif action == 'log_transform':
                    processed_df[column] = self.preprocessing_methods.log_transform(
                        processed_df[column], column)
                elif action == 'standard_scaler':
                    processed_df[column] = self.preprocessing_methods.standard_scaler(
                        processed_df[column], column)
                elif action == 'one_hot_encode':
                    encoded_df = self.preprocessing_methods.one_hot_encode(
                        processed_df[column], column)
                    processed_df = pd.concat([processed_df.drop(column, axis=1), encoded_df], axis=1)
                elif action == 'drop_column':
                    processed_df = processed_df.drop(column, axis=1)
                    
            except Exception as e:
                logger.error(f"ì¶”ì²œ ì ìš© ì‹¤íŒ¨ - {column}: {action}, ì˜¤ë¥˜: {e}")
                continue
        
        return processed_df

# Streamlit ì¸í„°í˜ì´ìŠ¤ êµ¬ì„± ìš”ì†Œ
class StreamlitRecommendationUI:
    """Streamlitìš© ì¶”ì²œ ì‹œìŠ¤í…œ UI ì»´í¬ë„ŒíŠ¸"""
    
    def __init__(self, integration: AutoMLIntegration):
        self.integration = integration
    
    def render_recommendation_panel(self, df: pd.DataFrame):
        """ì¶”ì²œ íŒ¨ë„ ë Œë”ë§"""
        
        st.subheader("ğŸ¤– AI ì „ì²˜ë¦¬ ì¶”ì²œ")
        
        # ì¶”ì²œ ìƒì„±
        with st.spinner("ë°ì´í„° ë¶„ì„ ì¤‘..."):
            result = self.integration.get_preprocessing_recommendations(df)
        
        # ìš”ì•½ ì •ë³´ í‘œì‹œ
        summary = result['summary']
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ì´ ì¶”ì²œìˆ˜", summary['total_recommendations'])
        with col2:
            st.metric("ë†’ì€ ìš°ì„ ìˆœìœ„", summary['high_priority'])
        with col3:
            st.metric("ì¤‘ê°„ ìš°ì„ ìˆœìœ„", summary['medium_priority'])
        with col4:
            st.metric("ë‚®ì€ ìš°ì„ ìˆœìœ„", summary['low_priority'])
        
        # ì¶”ì²œì‚¬í•­ í‘œì‹œ
        recommendations = result['recommendations']
        
        if recommendations:
            st.subheader("ğŸ“‹ ì¶”ì²œì‚¬í•­")
            
            # ì¶”ì²œì‚¬í•­ì„ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
            rec_df = pd.DataFrame(recommendations)
            
            # ìš°ì„ ìˆœìœ„ë³„ ìƒ‰ìƒ ë§¤í•‘
            def priority_color(priority):
                colors = {'high': 'ğŸ”´', 'medium': 'ğŸŸ¡', 'low': 'ğŸŸ¢'}
                return colors.get(priority, 'âšª')
            
            rec_df['priority_icon'] = rec_df['priority'].apply(priority_color)
            
            # ì„ íƒ ê°€ëŠ¥í•œ ì¶”ì²œì‚¬í•­ í‘œì‹œ
            selected_actions = []
            for i, rec in enumerate(recommendations):
                col1, col2 = st.columns([1, 4])
                with col1:
                    selected = st.checkbox(
                        f"{rec['priority_icon']} {rec['priority']}", 
                        key=f"rec_{i}",
                        value=rec['priority'] == 'high'  # ë†’ì€ ìš°ì„ ìˆœìœ„ëŠ” ê¸°ë³¸ ì„ íƒ
                    )
                with col2:
                    st.write(f"**{rec['column']}**: {rec['action']}")
                
                if selected:
                    selected_actions.append(rec['action'])
            
            # ì ìš© ë²„íŠ¼
            if st.button("ì„ íƒí•œ ì¶”ì²œì‚¬í•­ ì ìš©"):
                with st.spinner("ì „ì²˜ë¦¬ ì ìš© ì¤‘..."):
                    processed_df = self.integration.apply_recommendations_to_streamlit(
                        df, selected_actions)
                    st.success("ì „ì²˜ë¦¬ ì™„ë£Œ!")
                    return processed_df
        
        # ìƒì„±ëœ ì½”ë“œ í‘œì‹œ
        if st.expander("ğŸ”§ ìƒì„±ëœ ì½”ë“œ ë³´ê¸°"):
            st.code(result['executable_code'], language='python')
        
        return df

# ì‚¬ìš© ì˜ˆì‹œ í•¨ìˆ˜
def integrate_with_existing_automl():
    """ê¸°ì¡´ AutoML ì‹œìŠ¤í…œê³¼ì˜ í†µí•© ì˜ˆì‹œ"""
    
    # í†µí•© ê°ì²´ ìƒì„±
    integration = AutoMLIntegration()
    
    # Streamlit UI ìƒì„±
    ui = StreamlitRecommendationUI(integration)
    
    # ê¸°ì¡´ app.pyì— ì¶”ê°€í•  ì½”ë“œ
    example_code = """
    # ê¸°ì¡´ app.pyì˜ ë°ì´í„° ì—…ë¡œë“œ í›„ ì¶”ê°€í•  ì½”ë“œ
    
    if uploaded_file is not None:
        df = pd.read_csv(uploaded_file)
        
        # === ì¶”ê°€: AI ì „ì²˜ë¦¬ ì¶”ì²œ ì‹œìŠ¤í…œ ===
        integration = AutoMLIntegration()
        ui = StreamlitRecommendationUI(integration)
        
        # ì¶”ì²œ íŒ¨ë„ ë Œë”ë§
        processed_df = ui.render_recommendation_panel(df)
        
        # ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ê¸°ì¡´ AutoML ì‹œìŠ¤í…œì— ì „ë‹¬
        if processed_df is not None:
            updated_df = processed_df
        
        # === ê¸°ì¡´ AutoML ì½”ë“œ ê³„ì† ===
        # ... (ê¸°ì¡´ ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµ ì½”ë“œ)
    """
    
    print("ğŸ”— ê¸°ì¡´ AutoML ì‹œìŠ¤í…œê³¼ì˜ í†µí•© ë°©ë²•:")
    print(example_code)

if __name__ == "__main__":
    integrate_with_existing_automl() 