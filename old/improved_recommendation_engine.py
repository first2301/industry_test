import pandas as pd
import numpy as np
import yaml
from dataclasses import dataclass, field
from typing import Any, Dict, List, Tuple
import logging

logger = logging.getLogger(__name__)

@dataclass
class RuleSet:
    numeric: Dict[str, Any] = field(default_factory=dict)
    categorical: Dict[str, Any] = field(default_factory=dict)
    datetime: Dict[str, Any] = field(default_factory=dict)

    @classmethod
    def load(cls, path: str = "improved_rules.yaml") -> "RuleSet":
        with open(path, encoding="utf-8") as f:
            raw = yaml.safe_load(f)
        return cls(**raw)

class ImprovedPreprocessingRecommender:
    """ê°œì„ ëœ ì „ì²˜ë¦¬ ì¶”ì²œ ì‹œìŠ¤í…œ - ë” ì„¸ë¶„í™”ëœ ê·œì¹™ ì ìš©"""
    
    def __init__(self, rules: RuleSet):
        self.rules = rules
    
    def _apply_numeric_rules(self, col: str, s: pd.Series) -> List[Tuple[str, str]]:
        """ê°œì„ ëœ ìˆ˜ì¹˜í˜• ê·œì¹™ ì ìš©"""
        rec: List[Tuple[str, str]] = []
        r = self.rules.numeric
        
        # ê¸°ë³¸ í†µê³„ ê³„ì‚°
        miss = s.isna().mean()
        skew, kurt = s.skew(), s.kurtosis()
        mean, std = s.mean(), s.std()
        cv = std / mean if mean and not np.isnan(mean) and mean != 0 else np.inf
        unique_count = s.nunique()
        unique_ratio = unique_count / len(s)
        
        # 1. ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        for cond in r["missing_ratio"]:
            if miss > cond.get("gt", -np.inf):
                rec.append((cond["action"], cond["why"]))
                break
        
        # 2. ê°œì„ ëœ ì™œë„/ì²¨ë„ ê·œì¹™ - ë” ì„¸ë¶„í™”
        for cond in r["skew_kurt"]:
            skew_threshold = cond.get("skew", 0)
            kurt_threshold = cond.get("kurt", 1e9)
            
            # ì™œë„ì™€ ì²¨ë„ ëª¨ë‘ ì²´í¬
            if (abs(skew) > skew_threshold or kurt > kurt_threshold):
                rec.append((cond["action"], cond["why"]))
                break
        
        # 3. ë¶„ì‚° ê¸°ë°˜ ê·œì¹™
        for cond in r["variance"]:
            if cv < cond.get("cv_lt", -np.inf):
                rec.append((cond["action"], cond["why"]))
                break
        
        # 4. ë°ì´í„° íƒ€ì…ë³„ íŠ¹ë³„ ê·œì¹™
        if "data_type_specific" in r:
            for cond in r["data_type_specific"]:
                # ì»¬ëŸ¼ëª… ê¸°ë°˜ ê·œì¹™
                if "name_contains" in cond:
                    if cond["name_contains"].lower() in col.lower():
                        # ì¶”ê°€ ì¡°ê±´ ì²´í¬
                        if "skew_lt" in cond and skew < cond["skew_lt"]:
                            rec.append((cond["action"], cond["why"]))
                        elif "unique_lt" in cond and unique_count < cond["unique_lt"]:
                            rec.append((cond["action"], cond["why"]))
                        elif "unique_ratio_gt" in cond and unique_ratio > cond["unique_ratio_gt"]:
                            rec.append((cond["action"], cond["why"]))
                        else:
                            rec.append((cond["action"], cond["why"]))
        
        # 5. ì´ìƒì¹˜ íƒì§€ (í•­ìƒ ì²« ë²ˆì§¸ ë°©ë²•)
        if "outliers" in r and r["outliers"]:
            outlier_method = r["outliers"][0]
            rec.append((outlier_method["action"], outlier_method["why"]))
        
        # 6. ìŠ¤ì¼€ì¼ë§ (CV ê¸°ë°˜)
        if "scaling" in r:
            for cond in r["scaling"]:
                if cv > cond.get("cv_gt", np.inf):
                    rec.append((cond["action"], cond["why"]))
                    break
            else:
                # ê¸°ë³¸ ìŠ¤ì¼€ì¼ë§
                if r["scaling"]:
                    default_scaling = r["scaling"][-1]
                    rec.append((default_scaling["action"], default_scaling["why"]))
        
        return rec
    
    def _apply_categorical_rules(self, col: str, s: pd.Series) -> List[Tuple[str, str]]:
        """ê°œì„ ëœ ë²”ì£¼í˜• ê·œì¹™ ì ìš©"""
        rec: List[Tuple[str, str]] = []
        r = self.rules.categorical
        
        miss = s.isna().mean()
        unique = s.nunique(dropna=True)
        
        # 1. ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        for cond in r["missing_ratio"]:
            if miss > cond.get("gt", -np.inf):
                rec.append((cond["action"], cond["why"]))
                break
        
        # 2. ì¹´ë””ë„ë¦¬í‹° ê¸°ë°˜ ì¸ì½”ë”©
        for cond in r["cardinality"]:
            if ("lte" in cond and unique <= cond["lte"]) or ("gt" in cond and unique > cond["gt"]):
                rec.append((cond["action"], cond["why"]))
                break
        
        # 3. í…ìŠ¤íŠ¸ ë°ì´í„° íŠ¹ë³„ ê·œì¹™
        if "text_specific" in r:
            for cond in r["text_specific"]:
                if "name_contains" in cond and cond["name_contains"].lower() in col.lower():
                    rec.append((cond["action"], cond["why"]))
        
        return rec
    
    def recommend(self, df: pd.DataFrame) -> Dict[str, List[Dict[str, str]]]:
        """ê°œì„ ëœ ì¶”ì²œ ì‹œìŠ¤í…œ"""
        out: Dict[str, List[Dict[str, str]]] = {}
        
        numeric_cols = df.select_dtypes(include="number").columns
        categorical_cols = df.select_dtypes(include=["object", "category", "string"]).columns
        
        # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ì²˜ë¦¬
        for c in numeric_cols:
            rec = self._apply_numeric_rules(c, df[c].dropna())
            out[c] = [{"action": a, "why": w} for a, w in rec]
        
        # ë²”ì£¼í˜• ì»¬ëŸ¼ ì²˜ë¦¬
        for c in categorical_cols:
            rec = self._apply_categorical_rules(c, df[c])
            out[c] = [{"action": a, "why": w} for a, w in rec]
        
        return out

class ImprovedRecommendationEngine:
    """ê°œì„ ëœ ì¶”ì²œ ì—”ì§„"""
    
    def __init__(self, rule_path: str = "improved_rules.yaml"):
        self.rules = RuleSet.load(rule_path)
        self.preproc = ImprovedPreprocessingRecommender(self.rules)
    
    def run(self, df: pd.DataFrame) -> Dict[str, Any]:
        return {
            "preprocessing": self.preproc.recommend(df),
        }

# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_improved_recommendations():
    """ê°œì„ ëœ ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    print("=" * 80)
    print("ğŸ”§ ê°œì„ ëœ ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± (ì‹¤ì œ ë°ì´í„°ì™€ ìœ ì‚¬í•˜ê²Œ)
    np.random.seed(42)
    n_samples = 1000
    
    # ì‹¤ì œ ë°ì´í„°ì™€ ìœ ì‚¬í•œ íŠ¹ì„±ìœ¼ë¡œ ìƒì„±
    data = {
        'MIXA_PASTEUR_STATE': np.random.exponential(2, n_samples),  # ì™œë„ ~3
        'MIXB_PASTEUR_STATE': np.random.exponential(2, n_samples),  # ì™œë„ ~3
        'MIXA_PASTEUR_TEMP': -np.random.exponential(1, n_samples),  # ìŒìˆ˜ ì™œë„ ~-4
        'MIXB_PASTEUR_TEMP': -np.random.exponential(1, n_samples),  # ìŒìˆ˜ ì™œë„ ~-4
        'STD_DT': [f"2023-{i:02d}-{j:02d}" for i, j in zip(np.random.randint(1, 13, n_samples), np.random.randint(1, 29, n_samples))],
        'INSP': np.random.choice(['PASS', 'FAIL'], n_samples)
    }
    
    df = pd.DataFrame(data)
    
    # ê°œì„ ëœ ì—”ì§„ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
    engine = ImprovedRecommendationEngine()
    recommendations = engine.run(df)
    
    print("\nğŸ“Š ë°ì´í„° íŠ¹ì„±:")
    for col in df.select_dtypes(include=[np.number]).columns:
        skew = df[col].skew()
        kurt = df[col].kurtosis()
        print(f"  {col}: ì™œë„={skew:.2f}, ì²¨ë„={kurt:.2f}")
    
    print("\nğŸ¯ ê°œì„ ëœ ì¶”ì²œ ê²°ê³¼:")
    for col, recs in recommendations['preprocessing'].items():
        print(f"\nğŸ”¹ {col}:")
        for rec in recs:
            print(f"  âœ… {rec['action']}: {rec['why']}")
    
    return recommendations

if __name__ == "__main__":
    test_improved_recommendations() 