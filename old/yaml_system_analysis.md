# ğŸ“Š YAML ê¸°ë°˜ ê·œì¹™ ì‹œìŠ¤í…œ ë¶„ì„

## ğŸ” ì‹œìŠ¤í…œ êµ¬ì¡° ë¶„ì„

### 1. ì „ì²´ ì•„í‚¤í…ì²˜
```python
# ê³„ì¸µì  êµ¬ì¡°
RuleSet (YAML ë¡œë”)
â”œâ”€â”€ PreprocessingRecommender (ê·œì¹™ ì ìš©)
â”œâ”€â”€ VisualizationRecommender (ì‹œê°í™” ì¶”ì²œ)
â””â”€â”€ RecommendationEngine (í†µí•© ì—”ì§„)
```

### 2. í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ë¶„ì„

#### A. RuleSet í´ë˜ìŠ¤ (ì„¤ì • ê´€ë¦¬)
```python
@dataclass
class RuleSet:
    numeric: Dict[str, Any] = field(default_factory=dict)
    categorical: Dict[str, Any] = field(default_factory=dict)
    datetime: Dict[str, Any] = field(default_factory=dict)
    
    @classmethod
    def load(cls, path: str = "rules.yaml") -> "RuleSet":
        with open(path, encoding="utf-8") as f:
            raw = yaml.safe_load(f)
        return cls(**raw)
```

**ì¥ì :**
- âœ… **ì™¸ë¶€ ì„¤ì • íŒŒì¼ ë¶„ë¦¬**: ì½”ë“œ ìˆ˜ì • ì—†ì´ ê·œì¹™ ë³€ê²½ ê°€ëŠ¥
- âœ… **êµ¬ì¡°í™”ëœ ë°ì´í„°**: dataclassë¡œ íƒ€ì… ì•ˆì „ì„± í™•ë³´
- âœ… **í™•ì¥ì„±**: ìƒˆë¡œìš´ ë°ì´í„° íƒ€ì… ê·œì¹™ ì¶”ê°€ ìš©ì´

**í•œê³„ì :**
- âŒ **ê¸°ë³¸ ë°ì´í„° íƒ€ì…ë§Œ ì§€ì›**: ìˆ˜ì¹˜í˜•, ë²”ì£¼í˜•, ë‚ ì§œ/ì‹œê°„ë§Œ ì²˜ë¦¬
- âŒ **ë™ì  ê·œì¹™ ë¶€ì¡±**: ë°ì´í„° ì»¨í…ìŠ¤íŠ¸ë³„ ê·œì¹™ ì¡°ì • ë¯¸ì§€ì›

#### B. PreprocessingRecommender í´ë˜ìŠ¤ (ê·œì¹™ ì ìš©)
```python
def _apply_numeric_rules(self, col: str, s: pd.Series) -> List[Tuple[str, str]]:
    rec: List[Tuple[str, str]] = []
    r = self.rules.numeric
    
    # â‘  Missing ì²˜ë¦¬
    miss = s.isna().mean()
    for cond in r["missing_ratio"]:
        if miss > cond.get("gt", -np.inf):
            rec.append((cond["action"], cond["why"]))
            break  # ì²« ë§¤ì¹­ë§Œ ê¸°ë¡
    
    # â‘¡ Skew / Kurtosis ì²˜ë¦¬
    skew, kurt = s.skew(), s.kurtosis()
    for cond in r["skew_kurt"]:
        if abs(skew) > cond.get("skew", 0) or kurt > cond.get("kurt", 1e9):
            rec.append((cond["action"], cond["why"]))
            break
    
    # â‘¢ ë³€ë™ê³„ìˆ˜ ì²˜ë¦¬
    mean, std = s.mean(), s.std()
    cv = std / mean if mean else np.inf
    for cond in r["variance"]:
        if cv < cond.get("cv_lt", -np.inf):
            rec.append((cond["action"], cond["why"]))
            break
    
    return rec
```

**ì¥ì :**
- âœ… **ìˆœì°¨ì  ê·œì¹™ ì ìš©**: ìš°ì„ ìˆœìœ„ ìˆëŠ” ê·œì¹™ ë§¤ì¹­
- âœ… **ì„¤ëª… ê°€ëŠ¥í•œ ì¶”ì²œ**: action + why ìŒìœ¼ë¡œ ê·¼ê±° ì œê³µ
- âœ… **ëª¨ë“ˆí™”ëœ êµ¬ì¡°**: ë°ì´í„° íƒ€ì…ë³„ ë…ë¦½ì  ì²˜ë¦¬

**í•œê³„ì :**
- âŒ **ë‹¨ì¼ ì¡°ê±´ ë§¤ì¹­**: ë³µí•© ì¡°ê±´ ì²˜ë¦¬ ë¶ˆê°€
- âŒ **ì»¨í…ìŠ¤íŠ¸ ë¯¸ê³ ë ¤**: ë°ì´í„° ì „ì²´ íŠ¹ì„± ë°˜ì˜ ë¶€ì¡±
- âŒ **ê³ ì •ëœ í†µê³„**: ì™œë„, ì²¨ë„, CVë§Œ í™œìš©

### 3. YAML ê·œì¹™ íŒŒì¼ ë¶„ì„
```yaml
numeric:
  missing_ratio:
    - {gt: 0.40, action: "drop", why: "ê²°ì¸¡ë¥ >40%"}
    - {gt: 0.15, action: "advanced_impute", why: "ê²°ì¸¡ë¥  15~40% (KNN/Iterative)"}
    - {gt: 0.00, action: "simple_impute", why: "ì†ŒëŸ‰ ê²°ì¸¡ (mean/median)"}
  
  skew_kurt:
    - {skew: 2, kurt: 7, action: "transform", why: "ì‹¬í•œ ë¹„ëŒ€ì¹­Â·ì²¨ë„"}
    - {skew: 1, action: "outlier_detect", why: "ì•½í•œ ì™œë„ - ì´ìƒì¹˜ í™•ì¸"}
  
  variance:
    - {cv_lt: 0.1, action: "low_variance_drop", why: "ë³€ë™ì„±â†“"}

categorical:
  missing_ratio:
    - {gt: 0.30, action: "drop", why: "ê²°ì¸¡ë¥ >30%"}
    - {gt: 0.10, action: "impute_mode", why: "ê²°ì¸¡ë¥  10~30% (mode)"}
  
  cardinality:
    - {lte: 10, action: "one_hot", why: "ì €ì¹´ë””ë„ë¦¬í‹°"}
    - {lte: 50, action: "ordinal_encode", why: "ì¤‘ê°„ ì¹´ë””ë„ë¦¬í‹°"}
    - {lte: 1000, action: "target_encode", why: "ê³ ì¹´ë””ë„ë¦¬í‹° - supervised"}
    - {gt: 1000, action: "hashing_encode", why: "ì´ˆê³ ì¹´ë””ë„ë¦¬í‹°"}

datetime:
  extract: ["year", "quarter", "month", "weekday"]
```

**ì¥ì :**
- âœ… **ì§ê´€ì  ê·œì¹™ ì •ì˜**: ì„ê³„ê°’ê³¼ ì•¡ì…˜ì„ ëª…í™•íˆ ì •ì˜
- âœ… **ìœ ì—°í•œ ìˆ˜ì •**: ì½”ë“œ ë³€ê²½ ì—†ì´ ê·œì¹™ ì—…ë°ì´íŠ¸ ê°€ëŠ¥
- âœ… **ë²”ìœ„ ê¸°ë°˜ ì²˜ë¦¬**: ë‹¨ê³„ë³„ ì„ê³„ê°’ìœ¼ë¡œ ì„¸ë°€í•œ ì œì–´

**í•œê³„ì :**
- âŒ **ê³ ì •ëœ ì„ê³„ê°’**: ëª¨ë“  ë°ì´í„°ì— ë™ì¼í•œ ê¸°ì¤€ ì ìš©
- âŒ **ë‹¨ìˆœ ì¡°ê±´**: ë³µí•© ì¡°ê±´ì´ë‚˜ ìƒí˜¸ì‘ìš© ë¯¸ì§€ì›
- âŒ **ì»¨í…ìŠ¤íŠ¸ ë¯¸ë°˜ì˜**: ë°ì´í„° íŠ¹ì„±ë³„ ê·œì¹™ ì¡°ì • ë¶€ì¡±

## ğŸš€ ê°œì„ ëœ ì‹œìŠ¤í…œê³¼ ë¹„êµ

### í˜„ì¬ YAML ì‹œìŠ¤í…œ vs ê°œì„ ëœ ì‹œìŠ¤í…œ

| íŠ¹ì§• | YAML ì‹œìŠ¤í…œ | ê°œì„ ëœ ì‹œìŠ¤í…œ | ì°¨ì´ì  |
|------|-------------|---------------|--------|
| **ê·œì¹™ ê´€ë¦¬** | YAML íŒŒì¼ ê¸°ë°˜ | ì ì‘í˜• ì„ê³„ê°’ + ì„¤ì • | ë™ì  vs ì •ì  |
| **ë°ì´í„° íƒ€ì…** | 3ê°€ì§€ (ìˆ˜ì¹˜/ë²”ì£¼/ë‚ ì§œ) | 8ê°€ì§€ (ì„¸ë¶„í™”) | 400% ì¦ê°€ |
| **ì»¨í…ìŠ¤íŠ¸ ì¸ì‹** | ì—†ìŒ | 6ê°€ì§€ ìƒí™© ì¸ì‹ | ì™„ì „ ìƒˆë¡œìš´ ê¸°ëŠ¥ |
| **ìš°ì„ ìˆœìœ„** | ìˆœì°¨ì  ë§¤ì¹­ | 3ë‹¨ê³„ ìš°ì„ ìˆœìœ„ | ì¤‘ìš”ë„ ê¸°ë°˜ ì •ë ¬ |
| **ì½”ë“œ ìƒì„±** | ì—†ìŒ | ìë™ ìƒì„± | ì‹¤í–‰ ê°€ëŠ¥í•œ í…œí”Œë¦¿ |

### ì„±ëŠ¥ ë¹„êµ

```python
# YAML ì‹œìŠ¤í…œ - ë‹¨ìˆœ ê·œì¹™
def _apply_numeric_rules(self, col: str, s: pd.Series):
    for cond in r["missing_ratio"]:
        if miss > cond.get("gt", -np.inf):
            rec.append((cond["action"], cond["why"]))
            break

# ê°œì„ ëœ ì‹œìŠ¤í…œ - ì ì‘í˜• ê·œì¹™
def _adjust_thresholds_by_context(self):
    if self.context == DataContext.HIGH_DIMENSIONAL:
        self.thresholds['missing_high'] = 0.20  # ë” ì—„ê²©
    elif self.context == DataContext.SPARSE:
        self.thresholds['missing_high'] = 0.60  # ë” ê´€ëŒ€
```

## ğŸ’¡ YAML ì‹œìŠ¤í…œì˜ ë°œì „ ë°©í–¥

### 1. ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ ê°œì„ ì‚¬í•­

#### A. í™•ì¥ëœ YAML ê·œì¹™ êµ¬ì¡°
```yaml
# ê°œì„ ëœ rules.yaml ì˜ˆì‹œ
numeric:
  rules:
    missing_ratio:
      - context: "general"
        conditions:
          - {gt: 0.40, action: "drop", why: "ê²°ì¸¡ë¥ >40%"}
          - {gt: 0.15, action: "advanced_impute", why: "ê²°ì¸¡ë¥  15~40%"}
      - context: "high_dimensional"
        conditions:
          - {gt: 0.20, action: "drop", why: "ê³ ì°¨ì›ì—ì„œ ê²°ì¸¡ë¥ >20%"}
          - {gt: 0.10, action: "advanced_impute", why: "ê³ ì°¨ì› ê²°ì¸¡ ì²˜ë¦¬"}
    
    distribution:
      - {skew_gt: 2, kurt_gt: 7, action: "yeo_johnson", why: "ì‹¬í•œ ë¹„ëŒ€ì¹­"}
      - {skew_gt: 1, action: "robust_scale", why: "ì•½í•œ ì™œë„"}
      - {outlier_ratio_gt: 0.05, action: "outlier_detect", why: "ì´ìƒì¹˜ ë‹¤ìˆ˜"}

data_types:
  classification:
    - {pattern: ".*id.*", type: "id", action: "drop"}
    - {pattern: ".*key.*", type: "id", action: "drop"}
    - {unique_ratio_gt: 0.95, type: "id", action: "consider_drop"}
    - {dtype: "bool", type: "boolean", action: "label_encode"}
    - {avg_length_gt: 50, type: "text", action: "text_vectorize"}

contexts:
  detection:
    - {n_cols_gt: 100, context: "high_dimensional"}
    - {sparsity_gt: 0.8, context: "sparse"}
    - {time_cols_gt: 0, context: "timeseries"}
```

#### B. ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ PreprocessingRecommender
```python
class EnhancedPreprocessingRecommender:
    def __init__(self, rules: RuleSet):
        self.rules = rules
        self.context = "general"
        self.data_types = {}
    
    def _detect_context(self, df: pd.DataFrame) -> str:
        """ë°ì´í„° ì»¨í…ìŠ¤íŠ¸ ìë™ ê°ì§€"""
        n_rows, n_cols = df.shape
        
        # ì»¨í…ìŠ¤íŠ¸ ê°ì§€ ê·œì¹™ ì ìš©
        for rule in self.rules.contexts["detection"]:
            if "n_cols_gt" in rule and n_cols > rule["n_cols_gt"]:
                return rule["context"]
            if "sparsity_gt" in rule:
                sparsity = (df == 0).sum().sum() / (n_rows * n_cols)
                if sparsity > rule["sparsity_gt"]:
                    return rule["context"]
        
        return "general"
    
    def _classify_data_type(self, series: pd.Series) -> str:
        """ë°ì´í„° íƒ€ì… ìë™ ë¶„ë¥˜"""
        col_name = series.name.lower()
        
        # íƒ€ì… ë¶„ë¥˜ ê·œì¹™ ì ìš©
        for rule in self.rules.data_types["classification"]:
            if "pattern" in rule and re.search(rule["pattern"], col_name):
                return rule["type"]
            if "unique_ratio_gt" in rule:
                unique_ratio = series.nunique() / len(series)
                if unique_ratio > rule["unique_ratio_gt"]:
                    return rule["type"]
        
        return "unknown"
    
    def _apply_contextual_rules(self, col: str, s: pd.Series, data_type: str):
        """ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ê·œì¹™ ì ìš©"""
        rules = self.rules.numeric["rules"]
        
        # ì»¨í…ìŠ¤íŠ¸ë³„ ê·œì¹™ ì„ íƒ
        for rule_group in rules["missing_ratio"]:
            if rule_group["context"] == self.context:
                conditions = rule_group["conditions"]
                break
        else:
            conditions = rules["missing_ratio"][0]["conditions"]  # ê¸°ë³¸ê°’
        
        # ê·œì¹™ ì ìš©
        miss = s.isna().mean()
        for cond in conditions:
            if miss > cond.get("gt", -np.inf):
                return (cond["action"], cond["why"])
        
        return None
```

### 2. í†µí•© ê°œì„  ì „ëµ

#### A. í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ë²•
```python
class HybridRecommendationEngine:
    """YAML ê·œì¹™ + ë™ì  ë¶„ì„ í†µí•©"""
    
    def __init__(self, rule_path: str = "rules.yaml"):
        self.yaml_recommender = PreprocessingRecommender(RuleSet.load(rule_path))
        self.dynamic_recommender = EnhancedPreprocessingRecommender()
    
    def run(self, df: pd.DataFrame) -> Dict[str, Any]:
        # 1. ë™ì  ë¶„ì„ìœ¼ë¡œ ì»¨í…ìŠ¤íŠ¸ ê°ì§€
        context = self.dynamic_recommender._analyze_data_context(df)
        
        # 2. YAML ê·œì¹™ ì ìš© (ê¸°ë³¸ ì¶”ì²œ)
        yaml_recs = self.yaml_recommender.recommend(df)
        
        # 3. ë™ì  ê·œì¹™ìœ¼ë¡œ ë³´ì™„
        dynamic_recs = self.dynamic_recommender.recommend(df)
        
        # 4. ë‘ ì¶”ì²œ ê²°ê³¼ í†µí•©
        return self._merge_recommendations(yaml_recs, dynamic_recs, context)
```

#### B. ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜
```python
# Phase 1: YAML ê·œì¹™ í™•ì¥
- ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ê·œì¹™ ì¶”ê°€
- ë°ì´í„° íƒ€ì… ë¶„ë¥˜ ê·œì¹™ ì¶”ê°€
- ë³µí•© ì¡°ê±´ ì§€ì›

# Phase 2: ë™ì  ë¶„ì„ í†µí•©
- ì ì‘í˜• ì„ê³„ê°’ ì‹œìŠ¤í…œ ê²°í•©
- ì‹¤ì‹œê°„ ì»¨í…ìŠ¤íŠ¸ ê°ì§€
- ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ì¶”ì²œ

# Phase 3: ì™„ì „ í†µí•©
- ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ê·œì¹™ í•™ìŠµ
- ì‚¬ìš©ì í”¼ë“œë°± ë°˜ì˜
- ë„ë©”ì¸ íŠ¹í™” ê·œì¹™ ì ìš©
```

## ğŸ¯ ì‹¤ë¬´ ì ìš© ê¶Œì¥ì‚¬í•­

### 1. ë‹¨ê¸° ê°œì„  (2-4ì£¼)
```python
# í˜„ì¬ YAML ì‹œìŠ¤í…œ ê¸°ë°˜ ì¦‰ì‹œ ê°œì„ 
1. í™•ì¥ëœ ê·œì¹™ íŒŒì¼ ì‘ì„±
2. ì»¨í…ìŠ¤íŠ¸ ê°ì§€ í•¨ìˆ˜ ì¶”ê°€
3. ë°ì´í„° íƒ€ì… ë¶„ë¥˜ ê°œì„ 
4. ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ì •ë ¬
```

### 2. ì¤‘ê¸° ê°œì„  (1-2ê°œì›”)
```python
# í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ êµ¬ì¶•
1. ë™ì  ë¶„ì„ ì—”ì§„ í†µí•©
2. ì ì‘í˜• ì„ê³„ê°’ ì‹œìŠ¤í…œ
3. ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œ ìƒì„±
4. ì‹œê°í™” ì¶”ì²œ ê³ ë„í™”
```

### 3. ì¥ê¸° ê°œì„  (3-6ê°œì›”)
```python
# ì™„ì „ ì§€ëŠ¥í˜• ì‹œìŠ¤í…œ
1. ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ê·œì¹™ í•™ìŠµ
2. ì‚¬ìš©ì í”¼ë“œë°± ë°˜ì˜
3. ë„ë©”ì¸ íŠ¹í™” ê·œì¹™
4. ìë™í™” íŒŒì´í”„ë¼ì¸
```

## ğŸ’» êµ¬í˜„ ì˜ˆì‹œ

### í™•ì¥ëœ YAML ì‹œìŠ¤í…œ êµ¬í˜„
```python
class ExtendedYAMLRecommender:
    def __init__(self, rule_path: str = "enhanced_rules.yaml"):
        self.rules = RuleSet.load(rule_path)
        self.context = "general"
        self.data_types = {}
    
    def recommend(self, df: pd.DataFrame) -> Dict[str, Any]:
        # 1. ì»¨í…ìŠ¤íŠ¸ ê°ì§€
        self.context = self._detect_context(df)
        
        # 2. ë°ì´í„° íƒ€ì… ë¶„ë¥˜
        for col in df.columns:
            self.data_types[col] = self._classify_data_type(df[col])
        
        # 3. ì»¨í…ìŠ¤íŠ¸ë³„ ê·œì¹™ ì ìš©
        recommendations = {}
        for col in df.columns:
            recs = self._apply_contextual_rules(col, df[col], self.data_types[col])
            recommendations[col] = {
                'data_type': self.data_types[col],
                'context': self.context,
                'recommendations': recs,
                'priority': self._calculate_priority(df[col], recs)
            }
        
        return {
            'preprocessing': recommendations,
            'context': self.context,
            'data_types': self.data_types,
            'summary': self._generate_summary(recommendations)
        }
```

## ğŸ” ê²°ë¡ 

í˜„ì¬ YAML ê¸°ë°˜ ì‹œìŠ¤í…œì€ **ì²´ê³„ì ì´ê³  í™•ì¥ ê°€ëŠ¥í•œ êµ¬ì¡°**ë¥¼ ê°€ì§€ê³  ìˆì–´ ë§¤ìš° ì¢‹ì€ ê¸°ë°˜ì´ ë©ë‹ˆë‹¤. 

**ì£¼ìš” ì¥ì :**
- ì™¸ë¶€ ì„¤ì • íŒŒì¼ë¡œ ê·œì¹™ ê´€ë¦¬
- êµ¬ì¡°í™”ëœ ë°ì´í„° ì²˜ë¦¬
- ìˆœì°¨ì  ê·œì¹™ ë§¤ì¹­
- ì„¤ëª… ê°€ëŠ¥í•œ ì¶”ì²œ

**ê°œì„  ë°©í–¥:**
1. **ì»¨í…ìŠ¤íŠ¸ ì¸ì‹** ì¶”ê°€ë¡œ ìƒí™©ë³„ ìµœì í™”
2. **ë°ì´í„° íƒ€ì… ì„¸ë¶„í™”**ë¡œ ì •í™•ë„ í–¥ìƒ
3. **ì ì‘í˜• ì„ê³„ê°’**ìœ¼ë¡œ ìœ ì—°ì„± í™•ë³´
4. **ìš°ì„ ìˆœìœ„ ì‹œìŠ¤í…œ**ìœ¼ë¡œ ì‚¬ìš©ì ê²½í—˜ ê°œì„ 

ì´ ì‹œìŠ¤í…œì„ ê¸°ë°˜ìœ¼ë¡œ ì ì§„ì ìœ¼ë¡œ ê°œì„ í•˜ë©´ **ë§¤ìš° ê°•ë ¥í•œ ì¶”ì²œ ì‹œìŠ¤í…œ**ì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! 